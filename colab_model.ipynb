{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKD82xPMO5hC"
      },
      "source": [
        "# Initial Data Preparation for CT413 FYP\n",
        "\n",
        "1. Mounting Google Drive\n",
        "2. Read in individual data files\n",
        "3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRp11D2IfuK3",
        "outputId": "ece2cb32-8544-445c-bc50-ac1daa1a7dd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 13.6 gigabytes of available RAM\n",
            "\n",
            "Not using a high-RAM runtime\n"
          ]
        }
      ],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arYebX7pOqoJ"
      },
      "source": [
        "### Mounting Google Drive\n",
        "\n",
        "This will popup a prompt for permission to access google drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wOdjs5bOqQe"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFKh_eCzPykw"
      },
      "source": [
        "### Read in individual data files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKD1TAxMQD0h"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import dask.dataframe as dd\n",
        "\n",
        "# Path to folder of files\n",
        "folder_path = '/content/drive/MyDrive/SleepHealthDataTables/'\n",
        "\n",
        "# TODO:\n",
        "#\n",
        "# Read in certain columns from the data\n",
        "df_aeb = dd.read_csv(folder_path + 'active-energy-burned.csv', usecols=['participantId', 'timestamp', 'startTime', 'endTime', 'value'], assume_missing=True)\n",
        "df_aet = dd.read_csv(folder_path + 'apple-exercise-time.csv', usecols=['participantId', 'timestamp', 'startTime', 'endTime', 'value'], assume_missing=True)\n",
        "df_beb = dd.read_csv(folder_path + 'basal-energy-burned.csv', usecols=['participantId', 'timestamp', 'startTime', 'endTime', 'value'], assume_missing=True)\n",
        "df_bm = dd.read_csv(folder_path + 'body-mass.csv', usecols=['participantId', 'timestamp', 'startTime', 'endTime', 'value'], assume_missing=True)\n",
        "df_dwr = dd.read_csv(folder_path + 'distance-walking-running.csv', usecols=['participantId', 'timestamp', 'startTime', 'endTime', 'value'], assume_missing=True)\n",
        "df_fcl = dd.read_csv(folder_path + 'flights-climbed.csv', usecols=['participantId', 'timestamp', 'startTime', 'endTime', 'value'], assume_missing=True)\n",
        "df_hr = dd.read_csv(folder_path + 'heart-rate.csv', usecols=['participantId', 'timestamp', 'startTime', 'endTime', 'value'], assume_missing=True)\n",
        "'''\n",
        "df_h = dd.read_csv(folder_path + 'height.csv', usecols=['participantId', 'timestamp', 'startTime', 'endTime', 'value'], assume_missing=True)\n",
        "df_nt = dd.read_csv(folder_path + 'nap-tracker.csv', usecols=['participantId', 'timestamp', 'NapDuration', 'NapQuality'], assume_missing=True)\n",
        "df_sqc = dd.read_csv(folder_path + 'sleep-quality-checker.csv', usecols=['participantId', 'timestamp', 'sq_score'], assume_missing=True)\n",
        "df_sc = dd.read_csv(folder_path + 'step-count.csv', usecols=['participantId', 'timestamp', 'startTime', 'endTime', 'value'], assume_missing=True)\n",
        "'''\n",
        "\n",
        "timestamped_dfs = [df_aeb, df_aet, df_beb, df_bm, df_dwr, df_fcl, df_hr]\n",
        "#, df_h, df_nt, df_sqc, df_sc]\n",
        "\n",
        "# Make a list of Strings with the names of the dataframes\n",
        "df_names = ['active_energy_burned', 'apple_exercise_time', 'basal_energy_burned', 'body_mass', 'distance_walking_running', 'flights_climbed', 'heart_rate', 'height', 'nap_tracker', 'sleep_quality_checker', 'step_count']\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xp2q5K_VgCaj"
      },
      "outputs": [],
      "source": [
        "# Sort each dataframe by participantId\n",
        "for i, df in enumerate(timestamped_dfs):\n",
        "    timestamped_dfs[i] = df.sort_values('participantId')\n",
        "    # Convert startTime and endTime to datetime if they are in the df\n",
        "    if 'startTime' and 'endTime' in df:\n",
        "      df['timestamp'] = dd.to_datetime(df['timestamp'])\n",
        "    df['timestamp'] = dd.to_datetime(df['timestamp'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVWvvFxbnkk-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Merge and print the dataframe\n",
        "#\n",
        "# TODO:\n",
        "# When two tables are merged, delete df and original table from drive, and save new merged table\n",
        "#\n",
        "merged_timestamped = timestamped_dfs[0]\n",
        "for df in timestamped_dfs[1:]:\n",
        "  merged_timestamped = dd.merge(merged_timestamped, df, on=['participantId', 'timestamp'], how='outer', suffixes=('', '_y'))\n",
        "  del df\n",
        "\n",
        "merged_timestamped = merged_timestamped.compute()\n",
        "\n",
        "print(\"Merged Timestamped DataFrame:\")\n",
        "print(merged_timestamped)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ce8xKnNQLJCM"
      },
      "outputs": [],
      "source": [
        "# Create summary statistics for each dataframe for value column\n",
        "for idx, curr_df in enumerate(timestamped_dfs, start=1):\n",
        "    # Print the name of the dataframe\n",
        "    print(f\"\\nDataFrame {idx} Name: {df_names[idx-1]}\")\n",
        "    if 'value' in curr_df.columns:\n",
        "        print(curr_df['value'].describe())\n",
        "    elif 'sq_score' in curr_df.columns:\n",
        "        print(curr_df['sq_score'].describe())\n",
        "    elif 'NapQuality' in curr_df.columns:\n",
        "        print(curr_df['NapQuality'].describe())\n",
        "        print(curr_df['NapDuration'].describe())"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}